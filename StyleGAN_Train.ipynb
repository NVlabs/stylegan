{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StyleGAN_Train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwV-2YmQjXUx",
        "colab_type": "text"
      },
      "source": [
        "# **StyleGAN Train**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWhSx6VYi_pU",
        "colab_type": "text"
      },
      "source": [
        "This is a Colab notebook for training StyleGAN on a custom dataset.  For generating images from a trained model, use StyleGAN_Generate.ipynb:\n",
        "\n",
        "https://colab.research.google.com/github/NVlabs/stylegan/blob/master/StyleGAN_Generate.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dox2yDe4nHip",
        "colab_type": "text"
      },
      "source": [
        "Don't worry about this part, it's just setting things up."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYrZARNiOp_J",
        "colab_type": "code",
        "outputId": "9b7a4057-df0a-46c9-a82f-748cdbf52a24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "#use TensorFlow version 1.15.2\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# Download the code\n",
        "!git clone https://github.com/NVlabs/stylegan\n",
        "\n",
        "%cd stylegan\n",
        "!nvcc test_nvcc.cu -o test_nvcc -run\n",
        "\n",
        "print('Tensorflow version: {}'.format(tf.__version__) )\n",
        "print('GPU Identified at: {}'.format(tf.test.gpu_device_name()))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Cloning into 'stylegan'...\n",
            "remote: Enumerating objects: 83, done.\u001b[K\n",
            "remote: Total 83 (delta 0), reused 0 (delta 0), pack-reused 83\u001b[K\n",
            "Unpacking objects: 100% (83/83), done.\n",
            "/content/stylegan\n",
            "\u001b[01m\u001b[Kgcc:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Ktest_nvcc.cu: No such file or directory\n",
            "\u001b[01m\u001b[Kgcc:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K-x c++\u001b[m\u001b[K’ after last input file has no effect\n",
            "\u001b[01m\u001b[Kgcc:\u001b[m\u001b[K \u001b[01;31m\u001b[Kfatal error: \u001b[m\u001b[Kno input files\n",
            "compilation terminated.\n",
            "Tensorflow version: 1.15.2\n",
            "GPU Identified at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y65ADHwecA9n",
        "colab_type": "text"
      },
      "source": [
        "# Instructions:\n",
        "\n",
        "1.  Download a set of 20,000+ images of one type of thing.  For instance, dogs, flowers, etc.  Here are some ideas:\n",
        "\n",
        "http://vision.stanford.edu/aditya86/ImageNetDogs/\n",
        "\n",
        "https://www.robots.ox.ac.uk/~vgg/data/flowers/102/index.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmRzEMODP65k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcwEA80nQGbQ",
        "colab_type": "code",
        "outputId": "aaabe039-b914-4f12-f37a-c5f265aecaff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "cd datasets/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/stylegan/datasets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnmkPCAKmfED",
        "colab_type": "text"
      },
      "source": [
        "a. There is a little folder button all the way on the left side of the screen.  Click it.  Then, click the little down arrow next to the folder \"stylegan\".\n",
        "\n",
        "b. Now, drag and drop your images dataset into the \"datasets\" folder on the left."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8eKsacGm2I3",
        "colab_type": "text"
      },
      "source": [
        "c. Rename your images dataset folder to \"images_dataset\" by right-clicking on it in the file explorer on the left.\n",
        "\n",
        "d. Create another folder inside \"datasets\" by right-clicking on it and selecting \"new folder\".  Name this new folder \"images_tfrecords\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qh8yLubkf6ab",
        "colab_type": "text"
      },
      "source": [
        "Now, create tfrecords from the images.  This converts the images into data that Tensorflow can understand."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9nLGS2wmpxz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "python dataset_tool.py create_from_images datasets/images_tfrecords ./datasets/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJTULtn1oOwQ",
        "colab_type": "text"
      },
      "source": [
        "###After your tfrecords are created, download them.  You don't want to lose them!  Find them in the file window on the left, right-click, and click \"download\".  (Alternatively, you can mount your google drive and save them there.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaxwiYiegLya",
        "colab_type": "text"
      },
      "source": [
        "*Warning: training will take a long time.  Sometimes a whole day or two, depending on the size of the images you use and how many you want to train on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgNUPepcVlpw",
        "colab_type": "code",
        "outputId": "11a88d1b-6dfe-4751-a8d3-b21bce81ef3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 688
        }
      },
      "source": [
        "!python colab_train.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/stylegan/dnnlib/tflib/tfutil.py:34: The name tf.Dimension is deprecated. Please use tf.compat.v1.Dimension instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/stylegan/dnnlib/tflib/tfutil.py:74: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/stylegan/dnnlib/tflib/tfutil.py:128: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Creating the run dir root: results\n",
            "Creating the run dir: results/00000-sgan-Bizzownga-1gpu\n",
            "Copying files to the run dir\n",
            "dnnlib: Running training.training_loop.training_loop() on localhost...\n",
            "WARNING:tensorflow:From /content/stylegan/dnnlib/tflib/tfutil.py:97: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/stylegan/dnnlib/tflib/tfutil.py:109: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/stylegan/dnnlib/tflib/tfutil.py:132: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "Streaming data using training.dataset.TFRecordDataset...\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 191, in <module>\n",
            "    main()\n",
            "  File \"train.py\", line 186, in main\n",
            "    dnnlib.submit_run(**kwargs)\n",
            "  File \"/content/stylegan/dnnlib/submission/submit.py\", line 290, in submit_run\n",
            "    run_wrapper(submit_config)\n",
            "  File \"/content/stylegan/dnnlib/submission/submit.py\", line 242, in run_wrapper\n",
            "    util.call_func_by_name(func_name=submit_config.run_func_name, submit_config=submit_config, **submit_config.run_func_kwargs)\n",
            "  File \"/content/stylegan/dnnlib/util.py\", line 257, in call_func_by_name\n",
            "    return func_obj(*args, **kwargs)\n",
            "  File \"/content/stylegan/training/training_loop.py\", line 146, in training_loop\n",
            "    training_set = dataset.load_dataset(data_dir=config.data_dir, verbose=True, **dataset_args)\n",
            "  File \"/content/stylegan/training/dataset.py\", line 234, in load_dataset\n",
            "    dataset = dnnlib.util.get_obj_by_name(class_name)(**adjusted_kwargs)\n",
            "  File \"/content/stylegan/training/dataset.py\", line 70, in __init__\n",
            "    assert os.path.isdir(self.tfrecord_dir)\n",
            "AssertionError\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rANeta9ypWJo",
        "colab_type": "text"
      },
      "source": [
        "###This part will take a while.  As the .pkl files are generated, download them.  Also, you can download the .png image files and open them to see how your training is coming along.\n",
        "\n",
        "Google Colab only allows you to use it for 12 hours straight, or 24 hours if you have Colab Premium.  Make sure to set a timer so that you come back before the 12 (or 24) hours is up and you can save your .pkl file!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKHPDTUGlOxQ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "To generate images using your trained model, use StyleGAN_Generate.ipynb:\n",
        "\n",
        "https://colab.research.google.com/github/NVlabs/stylegan/blob/master/StyleGAN_Generate.ipynb"
      ]
    }
  ]
}